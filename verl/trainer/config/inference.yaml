# config/inference.yaml

# Model configuration
embedding:
  # Which embedding framework to use:
  #   'hf' → HuggingFace AutoModel (decoder-style)
  #   'st' → SentenceTransformer (encoder-style)
  framework: hf

  # Model information
  model:
    name: "BAAI/bge-base-en-v1.5"  # or any HF / SBERT name
  nnodes: 1
  n_gpus_per_node: 8

  # Output settings
  output_path: "./embeddings_output"

  # Processing parameters
  batch_size: 32
  max_length: 512        # Max tokens per text
  pooling_method: "mean" # only used when framework: hf
  normalize_embeddings: true

  # (optional) only used for SentenceTransformer
  # prompt_name: "web_search_query"

# Data configuration
data:
  path: "path/to/your/data.parquet"
  prompt_key: "prompt"
  train_ratio: 1.0
  train_ratio_seed: null

